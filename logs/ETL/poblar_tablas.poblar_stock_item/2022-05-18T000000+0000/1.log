[2022-05-19 02:00:49,464] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: ETL.poblar_tablas.poblar_stock_item scheduled__2022-05-18T00:00:00+00:00 [queued]>
[2022-05-19 02:00:49,550] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: ETL.poblar_tablas.poblar_stock_item scheduled__2022-05-18T00:00:00+00:00 [queued]>
[2022-05-19 02:00:49,574] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-05-19 02:00:49,589] {taskinstance.py:1250} INFO - Starting attempt 1 of 1
[2022-05-19 02:00:49,597] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-05-19 02:00:49,686] {taskinstance.py:1270} INFO - Executing <Task(PostgresOperator): poblar_tablas.poblar_stock_item> on 2022-05-18 00:00:00+00:00
[2022-05-19 02:00:49,774] {standard_task_runner.py:52} INFO - Started process 3107 to run task
[2022-05-19 02:00:49,821] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'ETL', 'poblar_tablas.poblar_stock_item', 'scheduled__2022-05-18T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/ELT.py', '--cfg-path', '/tmp/tmpbt13f5lv', '--error-file', '/tmp/tmpqy7xre1e']
[2022-05-19 02:00:49,854] {standard_task_runner.py:80} INFO - Job 30: Subtask poblar_tablas.poblar_stock_item
[2022-05-19 02:00:50,585] {logging_mixin.py:109} INFO - Running <TaskInstance: ETL.poblar_tablas.poblar_stock_item scheduled__2022-05-18T00:00:00+00:00 [running]> on host 096c3bc3ad3a
[2022-05-19 02:00:51,337] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=estudiante@uniandes.edu.co
AIRFLOW_CTX_DAG_OWNER=Estudiante
AIRFLOW_CTX_DAG_ID=ETL
AIRFLOW_CTX_TASK_ID=poblar_tablas.poblar_stock_item
AIRFLOW_CTX_EXECUTION_DATE=2022-05-18T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-18T00:00:00+00:00
[2022-05-19 02:00:51,363] {base.py:79} INFO - Using connection to: id: postgres_localhost. Host: host.docker.internal, Port: 5432, Schema: WWWIDWGrupo16, Login: Grupo16BI, Password: ***, extra: {}
[2022-05-19 02:00:51,710] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError
[2022-05-19 02:00:51,791] {taskinstance.py:1288} INFO - Marking task as FAILED. dag_id=ETL, task_id=poblar_tablas.poblar_stock_item, execution_date=20220518T000000, start_date=20220519T020049, end_date=20220519T020051
[2022-05-19 02:00:52,022] {standard_task_runner.py:98} ERROR - Failed to execute job 30 for task poblar_tablas.poblar_stock_item (; 3107)
[2022-05-19 02:00:52,164] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-19 02:00:52,232] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
