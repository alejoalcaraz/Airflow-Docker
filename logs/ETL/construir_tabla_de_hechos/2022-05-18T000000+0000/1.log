[2022-05-19 02:00:35,376] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: ETL.construir_tabla_de_hechos scheduled__2022-05-18T00:00:00+00:00 [queued]>
[2022-05-19 02:00:35,798] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: ETL.construir_tabla_de_hechos scheduled__2022-05-18T00:00:00+00:00 [queued]>
[2022-05-19 02:00:35,826] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-05-19 02:00:35,988] {taskinstance.py:1250} INFO - Starting attempt 1 of 1
[2022-05-19 02:00:36,052] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-05-19 02:00:36,182] {taskinstance.py:1270} INFO - Executing <Task(PostgresOperator): construir_tabla_de_hechos> on 2022-05-18 00:00:00+00:00
[2022-05-19 02:00:36,285] {standard_task_runner.py:52} INFO - Started process 3098 to run task
[2022-05-19 02:00:36,338] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'ETL', 'construir_tabla_de_hechos', 'scheduled__2022-05-18T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/ELT.py', '--cfg-path', '/tmp/tmpqth9hmz_', '--error-file', '/tmp/tmpqyppr1vo']
[2022-05-19 02:00:36,369] {standard_task_runner.py:80} INFO - Job 23: Subtask construir_tabla_de_hechos
[2022-05-19 02:00:37,832] {logging_mixin.py:109} INFO - Running <TaskInstance: ETL.construir_tabla_de_hechos scheduled__2022-05-18T00:00:00+00:00 [running]> on host 096c3bc3ad3a
[2022-05-19 02:00:39,220] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=estudiante@uniandes.edu.co
AIRFLOW_CTX_DAG_OWNER=Estudiante
AIRFLOW_CTX_DAG_ID=ETL
AIRFLOW_CTX_TASK_ID=construir_tabla_de_hechos
AIRFLOW_CTX_EXECUTION_DATE=2022-05-18T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-18T00:00:00+00:00
[2022-05-19 02:00:39,301] {base.py:79} INFO - Using connection to: id: postgres_localhost. Host: host.docker.internal, Port: 5432, Schema: WWWIDWGrupo16, Login: Grupo16BI, Password: ***, extra: {}
[2022-05-19 02:00:40,505] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError
[2022-05-19 02:00:40,683] {taskinstance.py:1288} INFO - Marking task as FAILED. dag_id=ETL, task_id=construir_tabla_de_hechos, execution_date=20220518T000000, start_date=20220519T020035, end_date=20220519T020040
[2022-05-19 02:00:41,029] {standard_task_runner.py:98} ERROR - Failed to execute job 23 for task construir_tabla_de_hechos (; 3098)
[2022-05-19 02:00:41,085] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-19 02:00:41,900] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
